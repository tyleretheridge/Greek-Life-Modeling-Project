Introduction
	The Duke University independent news organization *The Chronicle* published an [article](https://www.dukechronicle.com/article/2018/01/is-greek-life-at-duke-as-homogenous-as-you-think) titled "Is Greek life at Duke as homogenous as you think?" on January 19, 2018. This article dives into the diversity and background of students participating in Greek life at the university and how the distribution affects living groups. The authors Likhitha Butchireddygari and Jack Dolgin explore the relationships between home town, university majors, high school factors, and more in their work. A welcome byproduct of this hard data wrangling work is an MIT Licensed and publicly available [github repository](https://github.com/Chrissymbeck/Greek-Life-Demographics) with all of the data that was collected. Although there are Selective Living Groups that exist outside of Greek life, this project focuses only on the Greek life aspect.  


Purpose and Methodology
	Building off of the endeavor of exploring social patterns in the demographic of Duke's Selective Living Groups (SLGs) started by the writers at *The Chronicle*This project constructs a machine learning model that tries to classify a given student as either participating or not participating in an SLG based on various factors about the student's life before enrollment at Duke University. This exercise is split into four major components: data exploration, data engineering, model building, and visualization. All of the work in these components was accomplished using Python and multiple libraries and packages including, but not limited to, scikit-learn, Matplotlib, and pandas.
	
Data Exploration
	The data itself is a collection of 16 categories of information about each student in the Duke University Class of 2018 totaling 1,739 observations. The information includes each student's involvement in Greek Council, their home city location, various demographics about their high school, personal sports involvement and merit scholarships. For readability, the feature names included in this article are the names that appear in the original dataset published by the writers at *The Chronicle*. The main focus and classification target of this project is the `Greek Council` column, which lists a student's involvement in an SLG as either "None", "Sorority", or "Fraternity". The original creators of this curated dataset version made efforts to anonymize the students' personal information by excluding specific names of high schools. Furthermore, no gender, ethnic, or other self-identified information was included in the data to avoid invasions of privacy and perceived scrutiny of other minorities of any type. 
	As the data was explored, it became apparent that although the data does not contain explicit markers for demographics per student, the data does contain significant amounts of features that lend themselves to deep amounts of inference and utility for not only indirectly determining these demographics but also using them to develop patterns and mappings of diversity to involvement. The less obvious patterns and conclusions are the foundations on which the models in this project are built upon. Specific examples such as `Free and reduced percentage of High School`, `Public or Private High School`, `Tuition of High School`, and `Domestic or International High School` provide meaningful measures of a students' socioeconomic background or social mobility. 



Data Engineering
	At the core of every project is a well defined scope and targeted question to answer or a goal it aims to achieve. Although the original project in *The Chronicle* aimed to explore and discuss the diversity of students and how they fit into each specific section of the SLG ecosystem, this project has a narrower focus that is simply aiming to explore and classify any involvement in Greek life. It is this narrowed scope that directed most of the decisions in feature engineering and feature selection. Without highly specific information about each selective living group and personally identifying information about each student, it is impossible to develop a model that predicts specific organization involvement due to a wide variety of factors such as organizations catering to particular genders, majors and careers, cultures, or demographics. 
	To frame this narrowed scope in my dataset, the initial target column `Greek Council` was copied and had its values remapped to a binary classification of "Yes" or "No", with "Yes" being any entries previously labeled as "Fraternity" or "Sorority" and "No" being entries with "None" as their value. Keeping with this trend of adjusting values to account for lack of other information, the `Sports Team` feature was copied and stripped of the "Men's" and "Women's" classification leaving only the sport; however, both the original column and the division-less feature were used in modeling to explore any deviations from the expected class average based on gender divisions. 
	When beginning the feature selection process for modeling, many categories were found to contain either redundancy or data leakage. In the original dataset, if a student participated in either a fraternity or sorority, that student's specific organization was also included in a separate column. Due to the data in the `Greek Organization` column depending on a student's involvement value in the target feature, the data relating to specific organization involvement has been excluded from the model to avoid data leakage. Expanding on redundancy further, most students had a home city, state, and country listed. While these would provide useful statistics in terms of data exploration and storytelling, they were excluded in favor of `Latitude of Home City` and `Longitude of Home City`. Attempting to include these three categories alongside latitude and longitude would not only be redundant data, but it would also prevent challenges in encoding due to the encoding not necessarily maintaining the same relationships geographically that is inherent in already numerically expressed latitude and longitude coordinates. 


Model Building
	Three models were created to reflect the goal of classifying a given students' participation. The first model created was a simple majority class baseline model. After the target feature was reengineered into a binary classification, the values for each class were normalized, resulting in a 65.7% / 34.3% class split with "No" SLG involvement being the majority class. 
	Next, scikit-learn's `RandomForestClassifier()` was chosen as the preferred tree based model due to its flexibility, simplistic workflow with pipelines, and straightforward hyperparameters that are quickly tunable. After several rounds of hyperparameter tuning and cross validation, the random forest model slipped by the majority class baseline with a testing accuracy of 68.4%. 
	Finally, scikit-learn's `LogisticRegression()` linear model was chosen for the linear model. Unlike the tree based model, the linear model had little issue dashing beyond the baseline mark of 65.7% with its accuracy. Within just a couple of rounds of testing, the validation accuracy and ROC AUC scores passed the baseline, and the model exhibited 71.0% accuracy on the test set, a noticeable improvement. Although the two models' results do spell a victory over the baseline, the visualizations bring multiple new thoughts on what the data has to say.
Visualizations
	The visualization that is most interesting in this project is the confusion matrix. Although the confusion matrix does not convey the model's narrative like a feature importances or partial dependence plot would, it does say a lot about what the model struggled with. The Random forest classifier's confusion matrix shows a noticeably high false negative rate, with false negative prediction counts almost double that of false positive and true positive predictions. On the other hand, the linear model demonstrates a significantly higher false negative rate. The linear model gave false negative predictions at three times the rate of false positive and true positive predictions combined, but it correctly identified true negatives much better. This is where the discrepancy in the two models' accuracy becomes more interesting. The forest model valued a high school's tuition, religious denomination, public status, and boarding status as very important. The linear model valued boarding and tuition as well, but took much better to the sports encoding and valued it. 

Conclusion
	*The Chronicle's* original article's findings resonate strongly throughout the dataset. Even when framed in the context of trends of all students instead of the specific organizations, there is a persistent socioeconomic and demographic commonality that sets students apart in Greek Life participation. Although these models can not answer all of the questions about what makes a Greek life student at Duke University, they are able to identify the average student in a selective living group.

